{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import json\n",
    "from multiprocess import Pool\n",
    "from process_single_file import process_single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = ['train','val']\n",
    "\n",
    "path = '/Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open('label2id.json')\n",
    "label2id = json.load(fl)\n",
    "\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open('id2label.json')\n",
    "id2label = json.load(fl)\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_file(args):\n",
    "    print(\"inside process_single_file\")\n",
    "    each_file,each_folder,combined_folder_path,new_path = args\n",
    "    \n",
    "    print(combined_folder_path + each_folder + '/' +each_file)\n",
    "    fl = open(combined_folder_path + each_folder + '/' +each_file, 'a+')\n",
    "    json_obj = json.load(fl)\n",
    "    fl.close()\n",
    "    print(\"f1: \", f1)\n",
    "    \n",
    "    json_data = json_obj\n",
    "    img_height = json_data[\"imgHeight\"]\n",
    "    img_width = json_data[\"imgWidth\"]\n",
    "\n",
    "    # Create a blank image\n",
    "    image = Image.new(mode=\"L\",size= (img_width, img_height))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Draw polygons on the image\n",
    "    for obj in json_data[\"objects\"]:\n",
    "        if obj[\"draw\"]:\n",
    "            label = obj[\"label\"]\n",
    "            correct_id = label2id[label]\n",
    "            polygon = [(point[0], point[1]) for point in obj[\"polygon\"]]\n",
    "            draw.polygon(polygon,fill=correct_id)\n",
    "\n",
    "    image.save(new_path+'/'+each_folder+'/'+each_file.replace(\"json\",\"png\"))\n",
    "    \n",
    "    print(\"\\nprocessed image \",new_path+'/'+each_folder+'/'+each_file.replace(\"json\",\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.process_single_file(args)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_single_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_annotations(split):\n",
    "    \n",
    "    combined_path = path + 'gtFine/'+ split + '/'\n",
    "    new_path = path+'label_processed'+'/'+ split\n",
    "    print(\"combined_path: \", combined_path)\n",
    "    print(\"new_path: \", new_path)\n",
    "    \n",
    "    folders = os.listdir(combined_path)\n",
    "    print(\"Folders: \", folders)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(new_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(new_path, \" already exist\")\n",
    "\n",
    "    for each_folder in folders:\n",
    "        \n",
    "        combined_folder_path = combined_path+'/'+each_folder\n",
    "\n",
    "        files = os.listdir(combined_folder_path)\n",
    "        files = files[0:1]\n",
    "        print(\"File length is: \", len(files))\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(new_path+'/'+each_folder)\n",
    "        except:\n",
    "            print(new_path+'/'+each_folder,\" already exist\")\n",
    "\n",
    "        \n",
    "        pool_args = []\n",
    "        \n",
    "        for each_file in files:\n",
    "            \n",
    "            pool_args.append([each_file,each_folder,combined_folder_path,new_path])\n",
    "            \n",
    "        pool = Pool(processes=20)\n",
    "        pool.map(process_single_file,pool_args)\n",
    "        pool.close()\n",
    "        pool.join\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each:  train\n",
      "combined_path:  /Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/gtFine/train/\n",
      "new_path:  /Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/label_processed/train\n",
      "Folders:  ['.DS_Store', '3']\n",
      "[Errno 2] No such file or directory: '/Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/label_processed/train'\n",
      "/Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/label_processed/train  already exist\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/gtFine/train//.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m data_split:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meach: \u001b[39m\u001b[38;5;124m\"\u001b[39m, each)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mpreprocess_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43meach\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 21\u001b[0m, in \u001b[0;36mpreprocess_annotations\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m each_folder \u001b[38;5;129;01min\u001b[39;00m folders:\n\u001b[1;32m     19\u001b[0m     combined_folder_path \u001b[38;5;241m=\u001b[39m combined_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39meach_folder\n\u001b[0;32m---> 21\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_folder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     files \u001b[38;5;241m=\u001b[39m files[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile length is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(files))\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/Users/rajkrishnanv/study/CSC2516/CSC2516_Final_Project/data_subset/gtFine/train//.DS_Store'"
     ]
    }
   ],
   "source": [
    "for each in data_split:\n",
    "    print(\"each: \", each)\n",
    "    preprocess_annotations(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_annotations(split):\n",
    "    \n",
    "    combined_path = path+'gtFine/'+split+'/'\n",
    "    new_path = path+'label_processed'+'/'+split\n",
    "    \n",
    "    folders = os.listdir(combined_path)\n",
    "    print(\"Folders: \", folders)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(new_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(new_path, \" already exist\")\n",
    "\n",
    "    for each_folder in folders:\n",
    "        \n",
    "        combined_folder_path = combined_path+each_folder\n",
    "\n",
    "        files = os.listdir(combined_folder_path)\n",
    "        files = files[0:1] # process only the first file\n",
    "        print(\"File length is: \", len(files))\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(new_path+'/'+each_folder)\n",
    "        except:\n",
    "            print(new_path+'/'+each_folder,\" already exist\")\n",
    "\n",
    "        pool_args = []\n",
    "        \n",
    "        for each_file in files:\n",
    "            inp = [each_file,each_folder,combined_folder_path,new_path]\n",
    "            print(inp)\n",
    "            pool_args.append(inp)\n",
    "        \n",
    "        with Pool(processes=1) as pool:\n",
    "            # apply the process_single_file function to each set of arguments in pool_args\n",
    "            pool.map(process_single_file,pool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
